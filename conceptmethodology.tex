\subsection{Concept}

To make a formal proof, developed in some system $X$, accessible to
the users of other systems, the first step is to express the theory
$D[X]$, implemented in the system $X$, in the logical framework {\sf
  Dedukti}.  Then, we must instrument the system $X$ so that the proof
can be exported from it, as a piece of data, expressed as a proof in
$D[X]$ and included in {\sf Logipedia}. Next, we need to analyze this
proof in order to determine which symbols, axioms and rewrite rules of
$D[X]$ it actually uses and, thus, in which alternative theories it
can be expressed.  Finally, we must align its concepts with the
definitions already present in {\sf Logipedia} and decide where it
fits in the general structure of the encyclopedia.

Depending on the system $X$ we consider, more or less research needs
to be done, for instance to design the theory $D[X]$. Among the 15
systems we focus on, we plan to reach level 5 or 6 for 10 of them.
For the others, more research needs to be done and we plan to reach
level 3 only.

These goals require the expertise of computer scientists, logicians,
mathematicians who are experts on one theory or one system, and
specialists on logical frameworks, reverse mathematics, and concept
alignment.

\subsubsection{Description of the work package 1}

\subsubsection{Description of the work package 3}

\subsubsection{Description of the work package 4}

Automatic Theorem Proving (ATP) has a key role in this project.

{\em Per se}, many formal proofs nowadays rely on the use of automatic
provers. They cover various domains and various kinds of application,
{\em e.g.} combinatorial
mathematics~\cite{DBLP:journals/ai/KonevL15,DBLP:conf/sat/HeuleKM16},
where they are expected to solve one large propositional problem, or
proof of
programs~\cite{DBLP:conf/esop/FilliatreP13,DBLP:journals/pacmpl/ProtzenkoZRRWBD17},
where they are given thousands of small problems in a combination of
quantified theories.

In a complementary way, ATPs will be used to automatically make a
coherent whole out of {\sf Logipedia}. A fruitful interaction between
formal proofs requires low-level glue which falls in the scope of ATPs.
For instance, they will be employed to fill the holes that appear when
considering provers with various granularity, to reduce the gaps between
proof systems, and to discharge proofs of concept alignment (in close
interaction with the work package 6).

Finally, ATPs will also benefit from {\sf Logipedia}. Obviously, {\sf
  Logipedia} will be an extensive library of formal statements that can
be used and combined by ATPs in their proof search. This is not trivial
though: lemma selection is crucial to avoid an overhead. It can also be
a source of benchmarks to evaluate their expressivity and automation.
Lastly, {\sf Logipedia} and {\sf Dedukti} will form a framework to make
ATPs cooperate with each other and with other tools, in a safe way.


\paragraph{From ATPs to {\sf Dedukti}}

As for Interactive Theorem Provers, the consistency of this work
strongly relies on the ability for ATPs to export statements and proofs
in some theory in {\sf Dedukti}. We divide this aspect in two tasks.

\dots UNDER PROGRESS


\subsubsection{Description of the work package 7}

\subsubsection{Description of the work package 2}

\subsubsection{Description of the work package 5 and 6}

\subsection{Methodology}

The methodology is the same for integrating any library to {\sf Logipedia},
but due to a difference of readiness of the various systems we focus on,
our priorities are different.

\begin{enumerate}
\item We already know how to express most of the theories of {\sf Atelier B},
{\sf Coq}, {\sf FoCaLiZe}, {\sf HOL Light}, {\sf HOL4}, {\sf
Isabelle}, {\sf Matita}, and {\sf Rodin} in {\sf Dedukti}. We propose
to instrument these systems so that they can produce {\sf Dedukti}
proofs that we can include in {\sf Logipedia}.

\item
For other theories, such as those of {\sf Abella}, {\sf Agda}, {\sf
Lean}, {\sf Minlog}, {\sf Mizar}, {\sf PVS}, {\sf TLA+}, the work is
in progress, or not yet started.  So we must first understand how they
can be expressed in {\sf Dedukti}.

\item Besides the standard libraries of these systems, large libraries
  have been developed: the {\sf Isabelle Archive of formal Proofs} \cite{AFP},
  {\sf Flyspeck}\cite{Flyspeck}, {\sf MathComp}\cite{Mathcomp}, 
  {\sf CompCert} \cite{Compcert}, {\sf CakeML} \cite{CakeML}, ...  We aim to include
  some of these libraries in {\sf Logipedia}.
  
\item
Besides proof systems, we also want to include proofs coming from
automated theorem provers, SAT solvers, SMT solvers, and model
checkers.  So we must instrument some of these systems so that they
can produce {\sf Dedukti} proofs that we can include in {\sf
Logipedia}.

\item
We want to develop algorithms to analyze which symbol, axiom, rewrite
rule is used in each proof, and consequently in which system each proof
can be used. We also want to develop algorithms to eliminate some of the 
symbols, axioms, and rewrite rules used in a proof in order to be able to 
use it in more systems.


\item
Each library imported in {\sf Logipedia} will come with its own
definition of natural numbers, real numbers, etc. We want to develop
``concept alignments algorithms'' to transport theorems from one
structure to another isomorphic one.

\item 
Besides data, we propose to include in {\sf Logipedia}, metadata and
an inner structure.
\end{enumerate}


\subsubsection{Methodology of the work package 1}

\subsubsection{Methodology of the work package 3}

\subsubsection{Methodology of the work package 4}

\subsubsection{Methodology of the work package 7}

\subsubsection{Methodology of the work package 2}

\subsubsection{Methodology of the work package 5 and 6}


\subsection{Readiness of the project}

This idea of building such a standard for proofs has already been
investigated in the past, such as in the Qed manifesto \cite{Qed94}, but
has produced limited results.

Our thesis is that, since the
Qed project, the situation has radically changed. After
thirty years of research, we have an empirical evidence that most of
the formal proofs developed in one of these systems can also be
developed in another. We understand the relationship between the
theories implemented in these systems much better. We have developed
several logical frameworks, extending predicate logic, in which these
theories can be expressed. And we have developed reverse mathematics
algorithms to analyze which axioms and rules are used in each proofs
and algorithms, such as constructivization algorithms, to translate
proofs from one theory to another.


%%% Local Variables:
%%%   mode: latex
%%%   ispell-local-dictionary: "english"
%%% TeX-master: "propB"
%%% End:
